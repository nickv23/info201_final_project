predict(fit,data.frame(x=40),interval="prediction")
# Let's also provide an estimate and 95% confidence interval for the
# mean abrasive wear loss when austentite content is 40%
predict(fit,data.frame(x=40))
x <- c(5, 12, 14, 17, 23, 30, 40, 47, 55, 67, 72, 81, 96, 112, 127)
y <- c(4, 10, 13, 15, 15, 25, 27, 46, 38, 46, 53, 70, 82, 99, 100)
# Plot in scatterplot form
plot(x, y)
sxy <- sum(x*y)
sxy
sum(x)
sum(y)
length(x)
sxy <- sum(x*y) - ((sum(x)*sum(y)) / length(x))
sxy
sum(x*x)
sxx <- sum(x*x) - (sum(x)^2 / length(x))
b <- sxy / sxx
b
a <- mean(y) - b * mean(x)
mean(x)
syy <- sum(y*y) - (sum(y)^2 / length(y))
std <- syy - b * sxy
syy <- sum(y*y) - (sum(y)^2 / length(y))
ssresid <- syy - b * sxy
std <- ssresid / (length(x) - 2)
std
std <- sqrt(variance)
variance <- ssresid / (length(x) - 2)
std <- sqrt(variance)
std
syy
ssto <- syy
ssto
syy
# Number 11.22
x2 <- c(.11, .13, .14, .18, .29, .44, .67, .78, .93)
y2 <- c(1.72, 2.17, 2.33, 3, 5.17, 7.61, 11.17, 12.72, 14.78)
length(x2) == length(yz)
length(x2) == length(y2)
sxy2 <- sum(x2 * y2) - ((sum(x2) * sum(y2))/ length(x2))
sxy2
sxx2 <- sum(x2 * x2) - (sum(x2)^2) / length(x2))
sxx2 <- sum(x2 * x2) - (sum(x2)^2 / length(x2))
sxx2
sxx
mean(y2)
lm(y2~x2)
sxx2 <- sum(x2 * x2) - (sum(x2)^2 / length(x2))
sxxtest<-sum((x2-mean(x2))^2)
sxx2
sxxtest
mean(x2)
sxy2 <- sum(x2*y2) - ((sum(x2)*sum(y2)) / length(x2))
sxx2 <- sum(x2 * x2) - (sum(x2)^2 / length(x2))
sxy2
sxx2
sxy2/sxx2
sxy2
sxx2
lm(y2~x2)
.00757/.001926
# We just used a t-test of the slope. Now, let's obtain the confidence interval for
# the slope:
confint(fit)
predict(fit,data.frame(x=.4),interval="confidence")
predict(fit,data.frame(x=.4),interval="prediction")
fit <- lm(y2~x2)
predict(fit,data.frame(x=.4),interval="confidence")
predict(fit,data.frame(x=.4),interval="prediction")
fit <- lm(y2~x2)
fit
predict(fit,data.frame(x=.4),interval="confidence")
summary(fit)
mean(x2)
fit
class(fit)
confit(fit)
confint(fit)
# We just used a t-test of the slope. Now, let's obtain the confidence interval for
# the slope:
confint(fit)
# Fit the linear regression model:
fit<-lm(y~x)
# We just used a t-test of the slope. Now, let's obtain the confidence interval for
# the slope:
confint(fit)
predict(fit,data.frame(x=.4),interval="confidence")
predict(fit,data.frame(x=.4),interval="prediction")
predict(fit2,data.frame(x=.4),interval="confidence")
fit2 <- lm(y2~x2)
confint(fit2)
predict(fit2,data.frame(x=.4),interval="confidence")
newData <- data.frame(x=.4)
newData
predict(fit2,newData,interval="confidence")
fit2
fit
data.frame(x=40)
predict(fit2, newData,interval="confidence")
newData <- data.frame(x2=.4)
predict(fit2, newData,interval="confidence")
predict(fit2,newData,interval="prediction")
obscounts<-matrix(c(59.5,53.3,56.8,63.1,58.7,
55.2,59.1,52.8,54.5,
51.7,48.8,53.9,49,
60.6,58.5,55,65.2,61.3),4,5, byrow=T)
dat = read.table("http://faculty.washington.edu/lynb/StatMath390/9_1_dat.txt",header=TRUE)
dat
# C7.1
EC1 <- c(59.5,53.3,56.8,63.1,58.7)
EC2 <- c(55.2,59.1,52.8,54.5)
EC3 <- c(51.7,48.8,53.9,49)
EC4 <- c(60.6,58.5,55,65.2,61.3)
Data <- data.frame(
Y=c(EC1, EC2, EC3, EC4),
Site =factor(rep(c("EC 1.6", "EC 3.8", "EC 6", "Ec 10.2"), times=c(length(EC1), length(EC2),
length(EC3), length(EC4))))
)
aD
Data
View(Data)
Data <- data.frame(
Y=c(EC1, EC2, EC3, EC4),
EC_Level =factor(rep(c("1.6", "3.8", "6", "10.2"), times=c(length(EC1), length(EC2),
length(EC3), length(EC4))))
)
View(Data)
View(dat)
Data <- data.frame(
EC_Level =factor(rep(c("1.6", "3.8", "6", "10.2"),
Tomato=c(EC1, EC2, EC3, EC4), times=c(length(EC1), length(EC2),
length(EC3), length(EC4))))
)
Data <- data.frame(
EC_Level =factor(rep(c("1.6", "3.8", "6", "10.2"),
Tomato =c(EC1, EC2, EC3, EC4), times=c(length(EC1), length(EC2), length(EC3), length(EC4))))
)
EC_Level <- c(1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4)
Tomato_Yield <- c(59.5,53.3,56.8,63.1,58.7,55.2,59.1,52.8,54.5, 51.7,48.8,53.9,49,51.7,48.8,53.9,49  )
length(EC_Level)
length(Tomato_Yield)
EC_Level <- c(1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4)
Tomato_Yield <- c(59.5, 53.3, 56.8, 63.1, 58.7,
55.2, 59.1, 52.8, 54.5,
51.7, 48.8, 53.9, 49,
60.6, 58.5, 55, 65.2, 61.3)
length(Tomato_Yield)
Data <- data.frame(EC_Level = EC_Level, Tomato_Yield = Tomato_Yield)
View(Data)
Data <- data.frame(EC_Level = EC_Level, Tomato_Yield = Tomato_Yield)
aov.ec <- aov(Tomato_Yield~ as.factor(EC_Level), data=Data)
summary(aov.ec)
dat = read.table("http://faculty.washington.edu/lynb/StatMath390/9_1_dat.txt",header=TRUE)
aov.1 = aov(Vibration~ as.factor(Brand), data=dat)
# Remember "as.factor" is important. It tells R to treat Brand as a categorical variable
# with categories 1, 2, ..., 5
# instead of as a continuous variable with values 1, ..., 5
# With as.factor(Brand), the F-test has 4 numerator degrees of freedom (for 5-1 categories)
summary(aov.1)  # you can compare this to Table 9.1 in the textbook, or to doing it by hand further below
Data <- data.frame(EC_Level = EC_Level, Tomato_Yield = Tomato_Yield)
aov.ec <- aov(Tomato_Yield~ as.factor(EC_Level), data=Data)
summary(aov.ec)
# Part b
lin =lm(Tomato_Yield~factor(EC_Level), data=Data)
summary(lin)
# Part b
lin =lm(Tomato_Yield~as.factor(EC_Level), data=Data)
summary(lin)
ex.iron<-c(61,175,111,124,130,173,169,169,160,244,257,333,199)
ex.al<-c(13,21,24,23,64,38,33,61,39,71,112,88,54)
phos.adsorp<-c(4,18,14,18,26,26,21,30,28,36,65,62,40)
# plot the data
plot(data.frame(ex.iron,ex.al,phos.adsorp))
# fit the multiple linear regression model
fit<-lm(phos.adsorp~ex.iron+ex.al)
summary(fit)
# y = tomato yield
# x = EC level
plot(EC_Level, Tomato_Yield)
# C7.1
## part a
EC_Level <- c(1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4)
Tomato_Yield <- c(59.5, 53.3, 56.8, 63.1, 58.7,
55.2, 59.1, 52.8, 54.5,
51.7, 48.8, 53.9, 49,
60.6, 58.5, 55, 65.2, 61.3)
Data <- data.frame(EC_Level = EC_Level, Tomato_Yield = Tomato_Yield)
View(Data)
sim_lin <- lm(Tomato_Yield~as.factor(EC_Level))
summary(sim_lin)
# Input the data:
x<-c(4.6, 17.0, 17.4, 18.0, 18.5, 22.4,26.5, 30.0, 34.0, 38.8, 48.2, 63.5, 65.8,
73.9, 77.2, 79.8, 84.0)
y<-c(0.66, 0.92, 1.45, 1.03, 0.7, .73, 1.20, 0.8, 0.91, 1.19, 1.15, 1.12,
1.37, 1.45, 1.50, 1.36, 1.29)
# plot the data
plot(x,y)
# Fit the linear regression model:
fit<-lm(y~x)
summary(fit)
# y = tomato yield
# x = EC level
plot(EC_Level, Tomato_Yield)
sim_lin <- lm(Tomato_Yield~EC_Level)
summary(sim_lin)
sim_lin <- lm(Tomato_Yield~EC_Level)
summary(sim_lin)
# Input the data:
x<-c(4.6, 17.0, 17.4, 18.0, 18.5, 22.4,26.5, 30.0, 34.0, 38.8, 48.2, 63.5, 65.8,
73.9, 77.2, 79.8, 84.0)
y<-c(0.66, 0.92, 1.45, 1.03, 0.7, .73, 1.20, 0.8, 0.91, 1.19, 1.15, 1.12,
1.37, 1.45, 1.50, 1.36, 1.29)
# plot the data
plot(x,y)
# Fit the linear regression model:
fit<-lm(y~x)
summary(fit) # FIND MEAN INCREASE
confint(fit) # USE TO FIND CONFIDENCE INTERVAL
cor.test(y,x)  # POPULATION CORRELATION IS 0 OR NOT
summary(fit) # FIND MEAN INCREASE
# Let's also provide an estimate and 95% confidence interval for the
# mean abrasive wear loss when austentite content is 40%
predict(fit,data.frame(x=40))
# We estimate the mean abrasive wear loss is 1.090014 mm^3 when austentite
# content is 40%. Look at the plot. This seems reasonable.
predict(fit,data.frame(x=40),interval="confidence")
# Now, let's predict an individual abrasive wear loss when austentite content
# is 40%
predict(fit,data.frame(x=40),interval="prediction")
ex.iron<-c(61,175,111,124,130,173,169,169,160,244,257,333,199)
ex.al<-c(13,21,24,23,64,38,33,61,39,71,112,88,54)
phos.adsorp<-c(4,18,14,18,26,26,21,30,28,36,65,62,40)
# plot the data
plot(data.frame(ex.iron,ex.al,phos.adsorp))
# fit the multiple linear regression model
fit<-lm(phos.adsorp~ex.iron+ex.al)
summary(fit)
# or by using the confint function
confint(fit)    # (0.0465, 0.179)
# Below we input the data and regression y on x1, x2, x3, and x4:
press<-c(1.4,2.2,4.6,4.9,4.6,4.7,4.6,4.5,4.8,1.4,4.7,1.6,4.5,4.7,4.8,4.6,4.3,4.9,1.7,4.6,2.6,3.1,4.7,2.5,4.5,2.1,1.8,1.5,1.3,4.6)
formaldehyde<-c(8,2,7,10,7,7,7,5,4,5,8,2,4,6,10,4,4,10,5,8,10,2,6,7,5,8,4,6,4,7)
catalyst<-c(4,4,4,7,4,7,13,4,7,1,10,4,10,7,13,10,13,10,4,13,1,13,13,1,13,1,1,1,1,10)
temp<-c(100,180,180,120,180,180,140,160,140,100,140,100,180,120,180,160,100,120,100,140,180,140,180,120,140,160,180,160,100,100)
time<-c(1,7,1,5,5,1,1,7,3,7,3,3,3,7,3,5,7,7,1,1,1,1,7,7,1,7,7,1,1,7)
# plot the data
plot(data.frame(press,formaldehyde,catalyst,temp,time))
# We first fit the "full" model, the model with all 4 predictors.
fit.full<-lm(press~catalyst+temp+time+formaldehyde)
summary(fit.full)
# Then, we fit the "reduced" model, the model without time and formaldehyde.
fit.reduced<-lm(press~catalyst+temp)
summary(fit.reduced)
# Then, we fit the "reduced" model, the model without time and formaldehyde.
fit.reduced<-lm(press~catalyst+temp)
summary(fit.reduced)
# We first fit the "full" model, the model with all 4 predictors.
fit.full<-lm(press~catalyst+temp+time+formaldehyde)
summary(fit.full)
length(time)
# Input the data again
ex.iron<-c(61,175,111,124,130,173,169,169,160,244,257,333,199)
ex.al<-c(13,21,24,23,64,38,33,61,39,71,112,88,54)
phos.adsorp<-c(4,18,14,18,26,26,21,30,28,36,65,62,40)
# plot the data again
plot(data.frame(ex.iron,ex.al,phos.adsorp))
# fit the reduced model
fit.reduced<-lm(phos.adsorp~1)
summary(fit.reduced)
# fit the full model
fit.full<-lm(phos.adsorp~ex.iron+ex.al)
summary(fit.full) # notice the F-statistic for model utility (92.03)
# do the F-test for subset of predictors
SSEreduced<-17.61^2*(13-1)
SSEfull<-4.379^2*(13-3)
( (SSEreduced-SSEfull)/2 ) / (SSEfull/(13-3))
pf(92.03,2,10,lower.tail=F)
anova(fit.reduced,fit.full) # notice the F-statistic (92.03)
###############################################################################
##### Effect of collinearity in multiple linear regression
# Back in lab 4, we examined the effect of collinearity on the regression
# coefficients, using fake/simulated data.
# Recall the make.fit function from lab 4. It is modified here to report the
# standard error of one of the coefficients from a multiple linear regression
# model with 2 predictors, x1 and x2, when the correlation (r) between x1 and
# x2 is varied.
make.fit = function(r)  # This function takes in r (i.e. cor between x1, x2,
{                       # not between y and anything.)
library(MASS)
set.seed(1)
n=100
dat =  mvrnorm(n, rep(0, 2), matrix(c(1,r,r,1),2,2))
x1 = dat[,1] ; x2 = dat[,2]
beta1 = 2
beta2 = 3
y = 1 + beta1*x1 + beta2*x2 + rnorm(n,0,0.1)  # Make y data, and add noise.
lm.1 = lm( y ~ x1 + x2)               # Here we fit a plain through the data.
return(summary(lm.1)$coeff[2,2])      # return the std err of beta 1.
}
r = stderrbeta1 = numeric(99)        # Make a 99-dimensional array for storing r and
# standard error of the estimate of beta1 (stderrbeta1)
for(i in c(1:99)){         # Run make.fit() 99 times.
r[i] = i/100
stderrbeta1[i] = make.fit(r[i])
}
plot(r,stderrbeta1)
setwd("Desktop/INFO 201/info201_final_project/")
shiny::runApp('~/Desktop/testerFinalProj')
setwd("~/Desktop/INFO 201/info201_final_project")
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('~/Desktop/testerFinalProj')
runApp('~/Desktop/testerFinalProj')
runApp('college_information')
runApp('~/Desktop/testerFinalProj')
runApp('~/Desktop/testerFinalProj')
runApp('~/Desktop/testerFinalProj')
college_data <- read.csv("MERGED2016_17_PP.csv", stringsAsFactors = FALSE)
college_data <- read.csv("MERGED2016_17_PP.csv", stringsAsFactors = FALSE)
getwd()
college_data <- read.csv("college_information/MERGED2016_17_PP.csv", stringsAsFactors = FALSE)
View(college_data)
runApp('~/Desktop/testerFinalProj')
getwd()
runApp('~/Desktop/testerFinalProj')
runApp('~/Desktop/testerFinalProj')
class(college_data$STABBR)
runApp('~/Desktop/testerFinalProj')
runApp('~/Desktop/testerFinalProj')
state <- "AZ"
scores_ACT <- college_data %>%
filter(STABBR == state) %>%
select(INSTNM, CITY, STABBR, ACTCMMID, ACTENMID, ACTMTMID, ACTWRMID) %>%
rowwise() %>%
mutate(ACTCMMID = if(ACTCMMID == "NULL") "No Scores" else ACTCMMID) %>%
mutate(ACTENMID = if(ACTENMID == "NULL") "No Scores" else ACTENMID) %>%
mutate(ACTMTMID = if(ACTMTMID == "NULL") "No Scores" else ACTMTMID) %>%
mutate(ACTWRMID = if(ACTWRMID == "NULL") "No Scores" else ACTWRMID)
#***************************************************************************************************
# List of the schools in given state
score_school_list <- scores_ACT$INSTNM
# Get particular school
ACT_school <- "Phoenix College"
# Getting the particular school
scores_school_ACT <- scores_ACT %>%
filter(INSTNM == ACT_school)
#***************************************************************************************************
# Making my new data frame which contains the
# type of act score and the score
score_ACT_Type <- c("Cumulative", "English", "Math", "Writing")
score_ACT_actual_score <- c(scores_school_ACT$ACTCMMID, scores_school_ACT$ACTENMID,
scores_school_ACT$ACTMTMID, scores_school_ACT$ACTWRMID)
score_graph_data <- data.frame("TypeACT" = score_ACT_Type, "ACTScore" = score_ACT_actual_score)
# Making the color scheme for the bar graph
score_colors <- c("#CC0000", "#3333CC", "#99CCFF", "#00CCFF")
#***************************************************************************************************
# Making my titles for the graph
score_title <- paste0("ACT scores for ", ACT_school)
legend_title <- "ACT Score Type"
#***************************************************************************************************
# Make plot
ggplot(score_graph_data, aes(x=TypeACT, y=ACTScore, fill=TypeACT)) +
geom_bar(stat="identity") +
scale_fill_manual(legend_title, values=score_colors) +
theme(plot.title = element_text(color="black", size=14, face="bold"),
axis.title.x = element_text(color="black", size=12, face="bold"),
axis.title.y = element_text(color="black", size=12, face="bold"),
legend.title = element_text(color="black", size=10, face="bold")
)  +
labs(
title = score_title,
x="Type of ACT Score",
y="ACT Score"
)
runApp('~/Desktop/testerFinalProj')
runApp('~/Desktop/testerFinalProj')
runApp('~/Desktop/testerFinalProj')
runApp('~/Desktop/testerFinalProj')
runApp('~/Desktop/testerFinalProj')
runApp('college_information')
runApp('college_information')
runApp('college_information')
getwd()
runApp('college_information')
runApp('~/Desktop/testerFinalProj')
runApp('college_information')
runApp('college_information')
runApp('college_information')
# Input the data:
x<-c(4.6, 17.0, 17.4, 18.0, 18.5, 22.4,26.5, 30.0, 34.0, 38.8, 48.2, 63.5, 65.8,
73.9, 77.2, 79.8, 84.0)
y<-c(0.66, 0.92, 1.45, 1.03, 0.7, .73, 1.20, 0.8, 0.91, 1.19, 1.15, 1.12,
1.37, 1.45, 1.50, 1.36, 1.29)
# plot the data
plot(x,y)
# Fit the linear regression model:
fit<-lm(y~x)
summary(fit) # FIND MEAN INCREASE
libary(plotly)
install.packages("plotly")
runApp('college_information')
install.packages("shinythemese")
install.packages("shinythemes")
runApp('college_information')
runApp('college_information')
runApp('college_information')
runApp('college_information')
s
# note that the t-value of 3.93 can be obtained by dividing the estimate of the
# coefficient of x (0.00757) by the std.error (0.001926)
.00757/.001926
# and, the std.error (which is s_b, using the notation from lecture slides)
# can be computed as s_e/(sqrt(s_xx), where the "_e" means subscript "e":
se<-0.2031   # s_e, or "residual standard error"
sxx<-sum((x-mean(x))^2) # s_xx
se/sqrt(sxx) # std.error
confint(fit) # USE TO FIND CONFIDENCE INTERVAL
cor.test(y,x)  # POPULATION CORRELATION IS 0 OR NOT
# The sample correlation 0.7122403.
# The t-statistic is 3.9298 and the p-value is 0.001337. # Note that the
# t-statistic and p-value (rounded) are exactly the same as those from the
# t-test of the null hypothesis that the mean increase in y associated with
# a 1 unit increase in x is 0, in favor of the alternative that it is not 0.
# We can also do this "by hand" using the sample correlation and sample size,
# using the formulas in the text and from lecture:'
rr<-cor(y, x)
rr
# Let's also provide an estimate and 95% confidence interval for the
# mean abrasive wear loss when austentite content is 40%
predict(fit,data.frame(x=40))
# We estimate the mean abrasive wear loss is 1.090014 mm^3 when austentite
# content is 40%. Look at the plot. This seems reasonable.
predict(fit,data.frame(x=40),interval="confidence")
# Now, let's predict an individual abrasive wear loss when austentite content
# is 40%
predict(fit,data.frame(x=40),interval="prediction")
ex.iron<-c(61,175,111,124,130,173,169,169,160,244,257,333,199)
ex.al<-c(13,21,24,23,64,38,33,61,39,71,112,88,54)
phos.adsorp<-c(4,18,14,18,26,26,21,30,28,36,65,62,40)
# plot the data
plot(data.frame(ex.iron,ex.al,phos.adsorp))
# fit the multiple linear regression model
fit<-lm(phos.adsorp~ex.iron+ex.al)
summary(fit)
# or by using the confint function
confint(fit)    # (0.0465, 0.179)
# We can get an estimate and 95% confidence interval
# for the mean phosphate adsorption
# when extractable iron is 200 and extractable aluminum is 40:
predict(fit,data.frame(ex.iron=200,ex.al=40),interval="confidence")
# And, we can predict and get a 95% prediction interval
# for an individual phosphate adsorption
# when extractable iron is 200 and extractable aluminum is 40:
predict(fit,data.frame(ex.iron=200,ex.al=40),interval="prediction")
# Let's look at the fit again
fit<-lm(phos.adsorp~ex.iron+ex.al)
summary(fit)
# Below we input the data and regression y on x1, x2, x3, and x4:
press<-c(1.4,2.2,4.6,4.9,4.6,4.7,4.6,4.5,4.8,1.4,4.7,1.6,4.5,4.7,4.8,4.6,4.3,4.9,1.7,4.6,2.6,3.1,4.7,2.5,4.5,2.1,1.8,1.5,1.3,4.6)
formaldehyde<-c(8,2,7,10,7,7,7,5,4,5,8,2,4,6,10,4,4,10,5,8,10,2,6,7,5,8,4,6,4,7)
catalyst<-c(4,4,4,7,4,7,13,4,7,1,10,4,10,7,13,10,13,10,4,13,1,13,13,1,13,1,1,1,1,10)
temp<-c(100,180,180,120,180,180,140,160,140,100,140,100,180,120,180,160,100,120,100,140,180,140,180,120,140,160,180,160,100,100)
time<-c(1,7,1,5,5,1,1,7,3,7,3,3,3,7,3,5,7,7,1,1,1,1,7,7,1,7,7,1,1,7)
# plot the data
plot(data.frame(press,formaldehyde,catalyst,temp,time))
# We first fit the "full" model, the model with all 4 predictors.
fit.full<-lm(press~catalyst+temp+time+formaldehyde)
summary(fit.full)
# Then, we fit the "reduced" model, the model without time and formaldehyde.
fit.reduced<-lm(press~catalyst+temp)
summary(fit.reduced)
anova(fit.reduced,fit.full) # this does the test quickly
# Input the data again
ex.iron<-c(61,175,111,124,130,173,169,169,160,244,257,333,199)
ex.al<-c(13,21,24,23,64,38,33,61,39,71,112,88,54)
phos.adsorp<-c(4,18,14,18,26,26,21,30,28,36,65,62,40)
# plot the data again
plot(data.frame(ex.iron,ex.al,phos.adsorp))
# fit the reduced model
fit.reduced<-lm(phos.adsorp~1)
summary(fit.reduced)
# fit the full model
fit.full<-lm(phos.adsorp~ex.iron+ex.al)
summary(fit.full) # notice the F-statistic for model utility (92.03)
anova(fit.reduced,fit.full) # notice the F-statistic (92.03)
